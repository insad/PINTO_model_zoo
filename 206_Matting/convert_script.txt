python3 predict.py \
--config configs/modnet/modnet_mobilenetv2.yml \
--model_path pretrain/modnet-mobilenetv2.pdparams \
--crop_size 256 256

python3 predict.py \
--config configs/modnet/modnet_mobilenetv2.yml \
--model_path pretrain/modnet-mobilenetv2.pdparams \
--crop_size 384 384

python3 predict.py \
--config configs/modnet/modnet_mobilenetv2.yml \
--model_path pretrain/modnet-mobilenetv2.pdparams \
--crop_size 512 512

python3 predict.py \
--config configs/modnet/modnet_mobilenetv2.yml \
--model_path pretrain/modnet-mobilenetv2.pdparams \
--crop_size 640 640



python3 predict.py \
--config configs/modnet/modnet_hrnet_w18.yml \
--model_path pretrain/modnet-hrnet_w18.pdparams \
--crop_size 256 256

python3 predict.py \
--config configs/modnet/modnet_hrnet_w18.yml \
--model_path pretrain/modnet-hrnet_w18.pdparams \
--crop_size 384 384

python3 predict.py \
--config configs/modnet/modnet_hrnet_w18.yml \
--model_path pretrain/modnet-hrnet_w18.pdparams \
--crop_size 512 512

python3 predict.py \
--config configs/modnet/modnet_hrnet_w18.yml \
--model_path pretrain/modnet-hrnet_w18.pdparams \
--crop_size 640 640



python3 predict.py \
--config configs/modnet/modnet_resnet50_vd.yml \
--model_path pretrain/modnet-resnet50_vd.pdparams \
--crop_size 256 256

python3 predict.py \
--config configs/modnet/modnet_resnet50_vd.yml \
--model_path pretrain/modnet-resnet50_vd.pdparams \
--crop_size 384 384

python3 predict.py \
--config configs/modnet/modnet_resnet50_vd.yml \
--model_path pretrain/modnet-resnet50_vd.pdparams \
--crop_size 512 512

python3 predict.py \
--config configs/modnet/modnet_resnet50_vd.yml \
--model_path pretrain/modnet-resnet50_vd.pdparams \
--crop_size 640 640


MODEL=modnet_mobilenetv2
H=256
W=256
paddle2onnx \
--model_dir . \
--model_filename ${MODEL}_${H}x${W}.pdmodel \
--params_filename ${MODEL}_${H}x${W}.pdiparams \
--opset_version 11 \
--save_file ${MODEL}_${H}x${W}.onnx
H=384
W=384
paddle2onnx \
--model_dir . \
--model_filename ${MODEL}_${H}x${W}.pdmodel \
--params_filename ${MODEL}_${H}x${W}.pdiparams \
--opset_version 11 \
--save_file ${MODEL}_${H}x${W}.onnx
H=512
W=512
paddle2onnx \
--model_dir . \
--model_filename ${MODEL}_${H}x${W}.pdmodel \
--params_filename ${MODEL}_${H}x${W}.pdiparams \
--opset_version 11 \
--save_file ${MODEL}_${H}x${W}.onnx
H=640
W=640
paddle2onnx \
--model_dir . \
--model_filename ${MODEL}_${H}x${W}.pdmodel \
--params_filename ${MODEL}_${H}x${W}.pdiparams \
--opset_version 11 \
--save_file ${MODEL}_${H}x${W}.onnx

MODEL=modnet_hrnet_w18
H=256
W=256
paddle2onnx \
--model_dir . \
--model_filename ${MODEL}_${H}x${W}.pdmodel \
--params_filename ${MODEL}_${H}x${W}.pdiparams \
--opset_version 11 \
--save_file ${MODEL}_${H}x${W}.onnx
H=384
W=384
paddle2onnx \
--model_dir . \
--model_filename ${MODEL}_${H}x${W}.pdmodel \
--params_filename ${MODEL}_${H}x${W}.pdiparams \
--opset_version 11 \
--save_file ${MODEL}_${H}x${W}.onnx
H=512
W=512
paddle2onnx \
--model_dir . \
--model_filename ${MODEL}_${H}x${W}.pdmodel \
--params_filename ${MODEL}_${H}x${W}.pdiparams \
--opset_version 11 \
--save_file ${MODEL}_${H}x${W}.onnx
H=640
W=640
paddle2onnx \
--model_dir . \
--model_filename ${MODEL}_${H}x${W}.pdmodel \
--params_filename ${MODEL}_${H}x${W}.pdiparams \
--opset_version 11 \
--save_file ${MODEL}_${H}x${W}.onnx

MODEL=modnet_resnet50_vd
H=256
W=256
paddle2onnx \
--model_dir . \
--model_filename ${MODEL}_${H}x${W}.pdmodel \
--params_filename ${MODEL}_${H}x${W}.pdiparams \
--opset_version 11 \
--save_file ${MODEL}_${H}x${W}.onnx
H=384
W=384
paddle2onnx \
--model_dir . \
--model_filename ${MODEL}_${H}x${W}.pdmodel \
--params_filename ${MODEL}_${H}x${W}.pdiparams \
--opset_version 11 \
--save_file ${MODEL}_${H}x${W}.onnx
H=512
W=512
paddle2onnx \
--model_dir . \
--model_filename ${MODEL}_${H}x${W}.pdmodel \
--params_filename ${MODEL}_${H}x${W}.pdiparams \
--opset_version 11 \
--save_file ${MODEL}_${H}x${W}.onnx
H=640
W=640
paddle2onnx \
--model_dir . \
--model_filename ${MODEL}_${H}x${W}.pdmodel \
--params_filename ${MODEL}_${H}x${W}.pdiparams \
--opset_version 11 \
--save_file ${MODEL}_${H}x${W}.onnx

rm -f *.pd*
exit

docker run --gpus all -it --rm \
-v `pwd`:/home/user/workdir \
ghcr.io/pinto0309/openvino2tensorflow:latest

python3 -m onnxsim modnet_hrnet_w18_256x256.onnx modnet_hrnet_w18_256x256.onnx
python3 -m onnxsim modnet_hrnet_w18_384x384.onnx modnet_hrnet_w18_384x384.onnx
python3 -m onnxsim modnet_hrnet_w18_512x512.onnx modnet_hrnet_w18_512x512.onnx
python3 -m onnxsim modnet_hrnet_w18_640x640.onnx modnet_hrnet_w18_640x640.onnx

python3 -m onnxsim modnet_mobilenetv2_256x256.onnx modnet_mobilenetv2_256x256.onnx
python3 -m onnxsim modnet_mobilenetv2_384x384.onnx modnet_mobilenetv2_384x384.onnx
python3 -m onnxsim modnet_mobilenetv2_512x512.onnx modnet_mobilenetv2_512x512.onnx
python3 -m onnxsim modnet_mobilenetv2_640x640.onnx modnet_mobilenetv2_640x640.onnx

python3 -m onnxsim modnet_resnet50_vd_256x256.onnx modnet_resnet50_vd_256x256.onnx
python3 -m onnxsim modnet_resnet50_vd_384x384.onnx modnet_resnet50_vd_384x384.onnx
python3 -m onnxsim modnet_resnet50_vd_512x512.onnx modnet_resnet50_vd_512x512.onnx
python3 -m onnxsim modnet_resnet50_vd_640x640.onnx modnet_resnet50_vd_640x640.onnx



MODEL=modnet_hrnet_w18
H=256
W=256
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
mkdir -p ${MODEL}_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m ${MODEL}_${H}x${W}/openvino/FP16/${MODEL}_${H}x${W}.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o ${MODEL}_${H}x${W}/openvino/myriad/${MODEL}_${H}x${W}.blob

H=384
W=384
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
mkdir -p ${MODEL}_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m ${MODEL}_${H}x${W}/openvino/FP16/${MODEL}_${H}x${W}.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o ${MODEL}_${H}x${W}/openvino/myriad/${MODEL}_${H}x${W}.blob

H=512
W=512
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
mkdir -p ${MODEL}_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m ${MODEL}_${H}x${W}/openvino/FP16/${MODEL}_${H}x${W}.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o ${MODEL}_${H}x${W}/openvino/myriad/${MODEL}_${H}x${W}.blob

H=640
W=640
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
mkdir -p ${MODEL}_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m ${MODEL}_${H}x${W}/openvino/FP16/${MODEL}_${H}x${W}.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o ${MODEL}_${H}x${W}/openvino/myriad/${MODEL}_${H}x${W}.blob



MODEL=modnet_mobilenetv2
H=256
W=256
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
mkdir -p ${MODEL}_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m ${MODEL}_${H}x${W}/openvino/FP16/${MODEL}_${H}x${W}.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o ${MODEL}_${H}x${W}/openvino/myriad/${MODEL}_${H}x${W}.blob

H=384
W=384
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
mkdir -p ${MODEL}_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m ${MODEL}_${H}x${W}/openvino/FP16/${MODEL}_${H}x${W}.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o ${MODEL}_${H}x${W}/openvino/myriad/${MODEL}_${H}x${W}.blob

H=512
W=512
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
mkdir -p ${MODEL}_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m ${MODEL}_${H}x${W}/openvino/FP16/${MODEL}_${H}x${W}.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o ${MODEL}_${H}x${W}/openvino/myriad/${MODEL}_${H}x${W}.blob

H=640
W=640
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
mkdir -p ${MODEL}_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m ${MODEL}_${H}x${W}/openvino/FP16/${MODEL}_${H}x${W}.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o ${MODEL}_${H}x${W}/openvino/myriad/${MODEL}_${H}x${W}.blob



MODEL=modnet_resnet50_vd
H=256
W=256
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
mkdir -p ${MODEL}_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m ${MODEL}_${H}x${W}/openvino/FP16/${MODEL}_${H}x${W}.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o ${MODEL}_${H}x${W}/openvino/myriad/${MODEL}_${H}x${W}.blob

H=384
W=384
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
mkdir -p ${MODEL}_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m ${MODEL}_${H}x${W}/openvino/FP16/${MODEL}_${H}x${W}.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o ${MODEL}_${H}x${W}/openvino/myriad/${MODEL}_${H}x${W}.blob

H=512
W=512
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
mkdir -p ${MODEL}_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m ${MODEL}_${H}x${W}/openvino/FP16/${MODEL}_${H}x${W}.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o ${MODEL}_${H}x${W}/openvino/myriad/${MODEL}_${H}x${W}.blob

H=640
W=640
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
mkdir -p ${MODEL}_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m ${MODEL}_${H}x${W}/openvino/FP16/${MODEL}_${H}x${W}.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o ${MODEL}_${H}x${W}/openvino/myriad/${MODEL}_${H}x${W}.blob




MODEL=modnet_hrnet_w18
H=256
W=256
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
rm -rf saved_model
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_onnx \
--onnx_opset 11 \
--keep_input_tensor_in_nchw
mv saved_model/model_float32.onnx ${MODEL}_${H}x${W}
rm -rf saved_model
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}

H=384
W=384
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
rm -rf saved_model
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_onnx \
--onnx_opset 11 \
--keep_input_tensor_in_nchw
mv saved_model/model_float32.onnx ${MODEL}_${H}x${W}
rm -rf saved_model
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}

H=512
W=512
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
rm -rf saved_model
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_onnx \
--onnx_opset 11 \
--keep_input_tensor_in_nchw
mv saved_model/model_float32.onnx ${MODEL}_${H}x${W}
rm -rf saved_model
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}

H=640
W=640
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
rm -rf saved_model
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_onnx \
--onnx_opset 11 \
--keep_input_tensor_in_nchw
mv saved_model/model_float32.onnx ${MODEL}_${H}x${W}
rm -rf saved_model
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}



MODEL=modnet_mobilenetv2
H=256
W=256
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
rm -rf saved_model
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_onnx \
--onnx_opset 11 \
--keep_input_tensor_in_nchw
mv saved_model/model_float32.onnx ${MODEL}_${H}x${W}
rm -rf saved_model
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}

H=384
W=384
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
rm -rf saved_model
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_onnx \
--onnx_opset 11 \
--keep_input_tensor_in_nchw
mv saved_model/model_float32.onnx ${MODEL}_${H}x${W}
rm -rf saved_model
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}

H=512
W=512
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
rm -rf saved_model
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_onnx \
--onnx_opset 11 \
--keep_input_tensor_in_nchw
mv saved_model/model_float32.onnx ${MODEL}_${H}x${W}
rm -rf saved_model
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}

H=640
W=640
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
rm -rf saved_model
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_onnx \
--onnx_opset 11 \
--keep_input_tensor_in_nchw
mv saved_model/model_float32.onnx ${MODEL}_${H}x${W}
rm -rf saved_model
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}



MODEL=modnet_resnet50_vd
H=256
W=256
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
rm -rf saved_model
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_onnx \
--onnx_opset 11 \
--keep_input_tensor_in_nchw
mv saved_model/model_float32.onnx ${MODEL}_${H}x${W}
rm -rf saved_model
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}

MODEL=modnet_resnet50_vd
H=384
W=384
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
rm -rf saved_model
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_onnx \
--onnx_opset 11 \
--keep_input_tensor_in_nchw
mv saved_model/model_float32.onnx ${MODEL}_${H}x${W}
rm -rf saved_model
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}

MODEL=modnet_resnet50_vd
H=512
W=512
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
rm -rf saved_model
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_onnx \
--onnx_opset 11 \
--keep_input_tensor_in_nchw
mv saved_model/model_float32.onnx ${MODEL}_${H}x${W}
rm -rf saved_model
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}

MODEL=modnet_resnet50_vd
H=640
W=640
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
rm -rf saved_model
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_onnx \
--onnx_opset 11 \
--keep_input_tensor_in_nchw
mv saved_model/model_float32.onnx ${MODEL}_${H}x${W}
rm -rf saved_model
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}
