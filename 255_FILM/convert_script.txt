docker run --gpus all -it --rm \
-v `pwd`:/home/user/workdir \
ghcr.io/pinto0309/openvino2tensorflow:latest


cd L1
MODEL=film_net_L1

python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,-1,-1,3],x1:0[1,-1,-1,3] \
--saved-model saved_model \
--output ../${MODEL}_HxW.onnx

cp -r saved_model saved_model_bk

H=256
W=256
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=180
W=320
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=240
W=320
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=360
W=640
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=480
W=640
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=720
W=1280
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=1080
W=1920
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

rm -rf saved_model_bk
rm -rf saved_model
cd ..



cd Style
MODEL=film_net_Style

python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,-1,-1,3],x1:0[1,-1,-1,3] \
--saved-model saved_model \
--output ../${MODEL}_HxW.onnx

cp -r saved_model saved_model_bk

H=256
W=256
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=180
W=320
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=240
W=320
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=360
W=640
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=480
W=640
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=720
W=1280
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=1080
W=1920
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

rm -rf saved_model_bk
rm -rf saved_model
cd ..



cd VGG
MODEL=film_net_VGG

python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,-1,-1,3],x1:0[1,-1,-1,3] \
--saved-model saved_model \
--output ../${MODEL}_HxW.onnx

cp -r saved_model saved_model_bk

H=256
W=256
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=180
W=320
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=240
W=320
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=360
W=640
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=480
W=640
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=720
W=1280
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

H=1080
W=1920
saved_model_to_tflite \
--saved_model_dir_path saved_model \
--input_shapes [1,1],[1,${H},${W},3],[1,${H},${W},3] \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs
python -m tf2onnx.convert \
--opset 11 \
--inputs-as-nchw x0:0,x1:0 \
--inputs time:0[1,1],x0:0[1,${H},${W},3],x1:0[1,${H},${W},3] \
--saved-model saved_model \
--output tflite_from_saved_model/model_float32.onnx
python -m onnxsim \
tflite_from_saved_model/model_float32.onnx \
tflite_from_saved_model/model_float32.onnx
mv tflite_from_saved_model/* saved_model
rm -rf tflite_from_saved_model
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model/openvino/FP32 \
--model_name ${MODEL}_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model/openvino/FP16 \
--model_name ${MODEL}_${H}x${W}
mv saved_model ${MODEL}_${H}x${W}
cp -r saved_model_bk saved_model

rm -rf saved_model_bk
rm -rf saved_model
cd ..
