xhost +local: && \
docker run --gpus all -it --rm \
-v `pwd`:/home/user/workdir \
-v /tmp/.X11-unix/:/tmp/.X11-unix:rw \
--device /dev/video0:/dev/video0:mwr \
--net=host \
-e XDG_RUNTIME_DIR=$XDG_RUNTIME_DIR \
-e DISPLAY=$DISPLAY \
--privileged \
pinto0309/openvino2tensorflow:latest

cd workdir

MODEL=cepdof
H=608
W=608
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}/openvino/FP16

MODEL=cepdof
H=1024
W=1024
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}/openvino/FP16


MODEL=habbof
H=608
W=608
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}/openvino/FP16

MODEL=habbof
H=1024
W=1024
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}/openvino/FP16


MODEL=mw_r
H=608
W=608
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}/openvino/FP16

MODEL=mw_r
H=1024
W=1024
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}/openvino/FP16


============================================
MODEL=cepdof
H=608
W=608
openvino2tensorflow \
--model_path ${MODEL}/openvino/${H}x${W}/FP32/${MODEL}_${H}x${W}.xml \
--model_output_path ${MODEL}/saved_model_${H}x${W} \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_full_integer_quant_tflite \
--string_formulas_for_normalization 'data / 255' \
--output_integer_quant_type 'uint8' \
--weight_replacement_config replace_${H}x${W}.json

MODEL=habbof
H=608
W=608
openvino2tensorflow \
--model_path ${MODEL}/openvino/${H}x${W}/FP32/${MODEL}_${H}x${W}.xml \
--model_output_path ${MODEL}/saved_model_${H}x${W} \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_full_integer_quant_tflite \
--string_formulas_for_normalization 'data / 255' \
--output_integer_quant_type 'uint8' \
--weight_replacement_config replace_${H}x${W}.json

MODEL=mw_r
H=608
W=608
openvino2tensorflow \
--model_path ${MODEL}/openvino/${H}x${W}/FP32/${MODEL}_${H}x${W}.xml \
--model_output_path ${MODEL}/saved_model_${H}x${W} \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_full_integer_quant_tflite \
--string_formulas_for_normalization 'data / 255' \
--output_integer_quant_type 'uint8' \
--weight_replacement_config replace_${H}x${W}.json

============================================
MODEL=cepdof
H=1024
W=1024
openvino2tensorflow \
--model_path ${MODEL}/openvino/${H}x${W}/FP32/${MODEL}_${H}x${W}.xml \
--model_output_path ${MODEL}/saved_model_${H}x${W} \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_full_integer_quant_tflite \
--string_formulas_for_normalization 'data / 255' \
--output_integer_quant_type 'uint8' \
--weight_replacement_config replace_${H}x${W}.json

MODEL=habbof
H=1024
W=1024
openvino2tensorflow \
--model_path ${MODEL}/openvino/${H}x${W}/FP32/${MODEL}_${H}x${W}.xml \
--model_output_path ${MODEL}/saved_model_${H}x${W} \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_full_integer_quant_tflite \
--string_formulas_for_normalization 'data / 255' \
--output_integer_quant_type 'uint8' \
--weight_replacement_config replace_${H}x${W}.json

MODEL=mw_r
H=1024
W=1024
openvino2tensorflow \
--model_path ${MODEL}/openvino/${H}x${W}/FP32/${MODEL}_${H}x${W}.xml \
--model_output_path ${MODEL}/saved_model_${H}x${W} \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_full_integer_quant_tflite \
--string_formulas_for_normalization 'data / 255' \
--output_integer_quant_type 'uint8' \
--weight_replacement_config replace_${H}x${W}.json
