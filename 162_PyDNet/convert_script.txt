xhost +local: && \
docker run --gpus all -it --rm \
-v `pwd`:/home/user/workdir \
-v /tmp/.X11-unix/:/tmp/.X11-unix:rw \
--device /dev/video0:/dev/video0:mwr \
--net=host \
-e XDG_RUNTIME_DIR=$XDG_RUNTIME_DIR \
-e DISPLAY=$DISPLAY \
--privileged \
pinto0309/tflite2tensorflow:latest

cd workdir

MODEL=pydnet
H=192
W=320
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_pb
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_tftrt
python -m tf2onnx.convert \
--saved-model saved_model \
--output saved_model/model_float32.onnx \
--opset 11 \
--inputs-as-nchw im0:0
python3 -m onnxsim saved_model/model_float32.onnx saved_model/model_float32.onnx
mv saved_model saved_model_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model_${H}x${W}/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model_${H}x${W}/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model_${H}x${W}/openvino/FP16
mkdir -p saved_model_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m saved_model_${H}x${W}/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o saved_model_${H}x${W}/openvino/myriad/saved_model.blob
mv ${MODEL}_${H}x${W}.tflite saved_model_${H}x${W}/${MODEL}_${H}x${W}.tflite
rm ${MODEL}_${H}x${W}.json

MODEL=pydnet
H=256
W=320
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_pb
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_tftrt
python -m tf2onnx.convert \
--saved-model saved_model \
--output saved_model/model_float32.onnx \
--opset 11 \
--inputs-as-nchw im0:0
python3 -m onnxsim saved_model/model_float32.onnx saved_model/model_float32.onnx
mv saved_model saved_model_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model_${H}x${W}/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model_${H}x${W}/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model_${H}x${W}/openvino/FP16
mkdir -p saved_model_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m saved_model_${H}x${W}/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o saved_model_${H}x${W}/openvino/myriad/saved_model.blob
mv ${MODEL}_${H}x${W}.tflite saved_model_${H}x${W}/${MODEL}_${H}x${W}.tflite
rm ${MODEL}_${H}x${W}.json

MODEL=pydnet
H=384
W=640
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_pb
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_tftrt
python -m tf2onnx.convert \
--saved-model saved_model \
--output saved_model/model_float32.onnx \
--opset 11 \
--inputs-as-nchw im0:0
python3 -m onnxsim saved_model/model_float32.onnx saved_model/model_float32.onnx
mv saved_model saved_model_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model_${H}x${W}/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model_${H}x${W}/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model_${H}x${W}/openvino/FP16
mkdir -p saved_model_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m saved_model_${H}x${W}/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o saved_model_${H}x${W}/openvino/myriad/saved_model.blob
mv ${MODEL}_${H}x${W}.tflite saved_model_${H}x${W}/${MODEL}_${H}x${W}.tflite
rm ${MODEL}_${H}x${W}.json

MODEL=pydnet
H=448
W=640
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_pb
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_tftrt
python -m tf2onnx.convert \
--saved-model saved_model \
--output saved_model/model_float32.onnx \
--opset 11 \
--inputs-as-nchw im0:0
python3 -m onnxsim saved_model/model_float32.onnx saved_model/model_float32.onnx
mv saved_model saved_model_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model_${H}x${W}/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model_${H}x${W}/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model_${H}x${W}/openvino/FP16
mkdir -p saved_model_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m saved_model_${H}x${W}/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o saved_model_${H}x${W}/openvino/myriad/saved_model.blob
mv ${MODEL}_${H}x${W}.tflite saved_model_${H}x${W}/${MODEL}_${H}x${W}.tflite
rm ${MODEL}_${H}x${W}.json

MODEL=pydnet
H=512
W=640
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_pb
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_tftrt
python -m tf2onnx.convert \
--saved-model saved_model \
--output saved_model/model_float32.onnx \
--opset 11 \
--inputs-as-nchw im0:0
python3 -m onnxsim saved_model/model_float32.onnx saved_model/model_float32.onnx
mv saved_model saved_model_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model_${H}x${W}/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model_${H}x${W}/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model_${H}x${W}/openvino/FP16
mkdir -p saved_model_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m saved_model_${H}x${W}/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o saved_model_${H}x${W}/openvino/myriad/saved_model.blob
mv ${MODEL}_${H}x${W}.tflite saved_model_${H}x${W}/${MODEL}_${H}x${W}.tflite
rm ${MODEL}_${H}x${W}.json

MODEL=pydnet
H=704
W=1280
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_pb
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_tftrt
python -m tf2onnx.convert \
--saved-model saved_model \
--output saved_model/model_float32.onnx \
--opset 11 \
--inputs-as-nchw im0:0
python3 -m onnxsim saved_model/model_float32.onnx saved_model/model_float32.onnx
mv saved_model saved_model_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model_${H}x${W}/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model_${H}x${W}/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model_${H}x${W}/openvino/FP16
mkdir -p saved_model_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m saved_model_${H}x${W}/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o saved_model_${H}x${W}/openvino/myriad/saved_model.blob
mv ${MODEL}_${H}x${W}.tflite saved_model_${H}x${W}/${MODEL}_${H}x${W}.tflite
rm ${MODEL}_${H}x${W}.json

MODEL=pydnet
H=768
W=1280
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_pb
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
tflite2tensorflow \
--model_path ${MODEL}_${H}x${W}.tflite \
--flatc_path ../flatc \
--schema_path ../schema.fbs \
--output_tftrt
python -m tf2onnx.convert \
--saved-model saved_model \
--output saved_model/model_float32.onnx \
--opset 11 \
--inputs-as-nchw im0:0
python3 -m onnxsim saved_model/model_float32.onnx saved_model/model_float32.onnx
mv saved_model saved_model_${H}x${W}
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model_${H}x${W}/model_float32.onnx \
--data_type FP32 \
--output_dir saved_model_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model saved_model_${H}x${W}/model_float32.onnx \
--data_type FP16 \
--output_dir saved_model_${H}x${W}/openvino/FP16
mkdir -p saved_model_${H}x${W}/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m saved_model_${H}x${W}/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o saved_model_${H}x${W}/openvino/myriad/saved_model.blob
mv ${MODEL}_${H}x${W}.tflite saved_model_${H}x${W}/${MODEL}_${H}x${W}.tflite
rm ${MODEL}_${H}x${W}.json

