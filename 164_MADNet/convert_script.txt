xhost +local: && \
docker run --gpus all -it --rm \
-v `pwd`:/home/user/workdir \
-v /tmp/.X11-unix/:/tmp/.X11-unix:rw \
--device /dev/video0:/dev/video0:mwr \
--net=host \
-e XDG_RUNTIME_DIR=$XDG_RUNTIME_DIR \
-e DISPLAY=$DISPLAY \
--privileged \
pinto0309/openvino2tensorflow:latest

cd workdir

H=144
W=256
DATASET=kitti
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs \
--output_coreml
python3 -m tf2onnx.convert \
--opset 11 \
--tflite tflite_from_saved_model/model_float32.tflite \
--output tflite_from_saved_model/model_float32.onnx \
--inputs-as-nchw model/left_img,model/right_img
python3 -m onnxsim tflite_from_saved_model/model_float32.onnx tflite_from_saved_model/model_float32.onnx
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir tflite_from_saved_model/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir tflite_from_saved_model/openvino/FP16
mkdir -p tflite_from_saved_model/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m tflite_from_saved_model/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o tflite_from_saved_model/openvino/myriad/model.blob
mv tflite_from_saved_model/* saved_model_madnet_${DATASET}_${H}x${W}
cp -r saved_model_madnet_${DATASET}_${H}x${W}/variables tflite_from_saved_model
cp saved_model_madnet_${DATASET}_${H}x${W}/saved_model.pb tflite_from_saved_model
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_tftrt
mv tflite_from_saved_model/tensorrt_saved_model_float16 saved_model_madnet_${DATASET}_${H}x${W}
mv tflite_from_saved_model/tensorrt_saved_model_float32 saved_model_madnet_${DATASET}_${H}x${W}
rm -rf tflite_from_saved_model

H=180
W=320
DATASET=kitti
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs \
--output_coreml
python3 -m tf2onnx.convert \
--opset 11 \
--tflite tflite_from_saved_model/model_float32.tflite \
--output tflite_from_saved_model/model_float32.onnx \
--inputs-as-nchw model/left_img,model/right_img
python3 -m onnxsim tflite_from_saved_model/model_float32.onnx tflite_from_saved_model/model_float32.onnx
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir tflite_from_saved_model/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir tflite_from_saved_model/openvino/FP16
mkdir -p tflite_from_saved_model/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m tflite_from_saved_model/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o tflite_from_saved_model/openvino/myriad/model.blob
mv tflite_from_saved_model/* saved_model_madnet_${DATASET}_${H}x${W}
cp -r saved_model_madnet_${DATASET}_${H}x${W}/variables tflite_from_saved_model
cp saved_model_madnet_${DATASET}_${H}x${W}/saved_model.pb tflite_from_saved_model
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_tftrt
mv tflite_from_saved_model/tensorrt_saved_model_float16 saved_model_madnet_${DATASET}_${H}x${W}
mv tflite_from_saved_model/tensorrt_saved_model_float32 saved_model_madnet_${DATASET}_${H}x${W}
rm -rf tflite_from_saved_model

H=216
W=384
DATASET=kitti
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs \
--output_coreml
python3 -m tf2onnx.convert \
--opset 11 \
--tflite tflite_from_saved_model/model_float32.tflite \
--output tflite_from_saved_model/model_float32.onnx \
--inputs-as-nchw model/left_img,model/right_img
python3 -m onnxsim tflite_from_saved_model/model_float32.onnx tflite_from_saved_model/model_float32.onnx
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir tflite_from_saved_model/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir tflite_from_saved_model/openvino/FP16
mkdir -p tflite_from_saved_model/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m tflite_from_saved_model/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o tflite_from_saved_model/openvino/myriad/model.blob
mv tflite_from_saved_model/* saved_model_madnet_${DATASET}_${H}x${W}
cp -r saved_model_madnet_${DATASET}_${H}x${W}/variables tflite_from_saved_model
cp saved_model_madnet_${DATASET}_${H}x${W}/saved_model.pb tflite_from_saved_model
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_tftrt
mv tflite_from_saved_model/tensorrt_saved_model_float16 saved_model_madnet_${DATASET}_${H}x${W}
mv tflite_from_saved_model/tensorrt_saved_model_float32 saved_model_madnet_${DATASET}_${H}x${W}
rm -rf tflite_from_saved_model

H=240
W=320
DATASET=kitti
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs \
--output_coreml
python3 -m tf2onnx.convert \
--opset 11 \
--tflite tflite_from_saved_model/model_float32.tflite \
--output tflite_from_saved_model/model_float32.onnx \
--inputs-as-nchw model/left_img,model/right_img
python3 -m onnxsim tflite_from_saved_model/model_float32.onnx tflite_from_saved_model/model_float32.onnx
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir tflite_from_saved_model/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir tflite_from_saved_model/openvino/FP16
mkdir -p tflite_from_saved_model/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m tflite_from_saved_model/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o tflite_from_saved_model/openvino/myriad/model.blob
mv tflite_from_saved_model/* saved_model_madnet_${DATASET}_${H}x${W}
cp -r saved_model_madnet_${DATASET}_${H}x${W}/variables tflite_from_saved_model
cp saved_model_madnet_${DATASET}_${H}x${W}/saved_model.pb tflite_from_saved_model
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_tftrt
mv tflite_from_saved_model/tensorrt_saved_model_float16 saved_model_madnet_${DATASET}_${H}x${W}
mv tflite_from_saved_model/tensorrt_saved_model_float32 saved_model_madnet_${DATASET}_${H}x${W}
rm -rf tflite_from_saved_model

H=270
W=480
DATASET=kitti
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs \
--output_coreml
python3 -m tf2onnx.convert \
--opset 11 \
--tflite tflite_from_saved_model/model_float32.tflite \
--output tflite_from_saved_model/model_float32.onnx \
--inputs-as-nchw model/left_img,model/right_img
python3 -m onnxsim tflite_from_saved_model/model_float32.onnx tflite_from_saved_model/model_float32.onnx
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir tflite_from_saved_model/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir tflite_from_saved_model/openvino/FP16
mkdir -p tflite_from_saved_model/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m tflite_from_saved_model/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o tflite_from_saved_model/openvino/myriad/model.blob
mv tflite_from_saved_model/* saved_model_madnet_${DATASET}_${H}x${W}
cp -r saved_model_madnet_${DATASET}_${H}x${W}/variables tflite_from_saved_model
cp saved_model_madnet_${DATASET}_${H}x${W}/saved_model.pb tflite_from_saved_model
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_tftrt
mv tflite_from_saved_model/tensorrt_saved_model_float16 saved_model_madnet_${DATASET}_${H}x${W}
mv tflite_from_saved_model/tensorrt_saved_model_float32 saved_model_madnet_${DATASET}_${H}x${W}
rm -rf tflite_from_saved_model

H=288
W=512
DATASET=kitti
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs \
--output_coreml
python3 -m tf2onnx.convert \
--opset 11 \
--tflite tflite_from_saved_model/model_float32.tflite \
--output tflite_from_saved_model/model_float32.onnx \
--inputs-as-nchw model/left_img,model/right_img
python3 -m onnxsim tflite_from_saved_model/model_float32.onnx tflite_from_saved_model/model_float32.onnx
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir tflite_from_saved_model/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir tflite_from_saved_model/openvino/FP16
mkdir -p tflite_from_saved_model/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m tflite_from_saved_model/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o tflite_from_saved_model/openvino/myriad/model.blob
mv tflite_from_saved_model/* saved_model_madnet_${DATASET}_${H}x${W}
cp -r saved_model_madnet_${DATASET}_${H}x${W}/variables tflite_from_saved_model
cp saved_model_madnet_${DATASET}_${H}x${W}/saved_model.pb tflite_from_saved_model
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_tftrt
mv tflite_from_saved_model/tensorrt_saved_model_float16 saved_model_madnet_${DATASET}_${H}x${W}
mv tflite_from_saved_model/tensorrt_saved_model_float32 saved_model_madnet_${DATASET}_${H}x${W}
rm -rf tflite_from_saved_model

H=306
W=408
DATASET=kitti
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs \
--output_coreml
python3 -m tf2onnx.convert \
--opset 11 \
--tflite tflite_from_saved_model/model_float32.tflite \
--output tflite_from_saved_model/model_float32.onnx \
--inputs-as-nchw model/left_img,model/right_img
python3 -m onnxsim tflite_from_saved_model/model_float32.onnx tflite_from_saved_model/model_float32.onnx
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir tflite_from_saved_model/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir tflite_from_saved_model/openvino/FP16
mkdir -p tflite_from_saved_model/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m tflite_from_saved_model/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o tflite_from_saved_model/openvino/myriad/model.blob
mv tflite_from_saved_model/* saved_model_madnet_${DATASET}_${H}x${W}
cp -r saved_model_madnet_${DATASET}_${H}x${W}/variables tflite_from_saved_model
cp saved_model_madnet_${DATASET}_${H}x${W}/saved_model.pb tflite_from_saved_model
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_tftrt
mv tflite_from_saved_model/tensorrt_saved_model_float16 saved_model_madnet_${DATASET}_${H}x${W}
mv tflite_from_saved_model/tensorrt_saved_model_float32 saved_model_madnet_${DATASET}_${H}x${W}
rm -rf tflite_from_saved_model

H=360
W=480
DATASET=kitti
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs \
--output_coreml
python3 -m tf2onnx.convert \
--opset 11 \
--tflite tflite_from_saved_model/model_float32.tflite \
--output tflite_from_saved_model/model_float32.onnx \
--inputs-as-nchw model/left_img,model/right_img
python3 -m onnxsim tflite_from_saved_model/model_float32.onnx tflite_from_saved_model/model_float32.onnx
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir tflite_from_saved_model/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir tflite_from_saved_model/openvino/FP16
mkdir -p tflite_from_saved_model/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m tflite_from_saved_model/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o tflite_from_saved_model/openvino/myriad/model.blob
mv tflite_from_saved_model/* saved_model_madnet_${DATASET}_${H}x${W}
cp -r saved_model_madnet_${DATASET}_${H}x${W}/variables tflite_from_saved_model
cp saved_model_madnet_${DATASET}_${H}x${W}/saved_model.pb tflite_from_saved_model
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_tftrt
mv tflite_from_saved_model/tensorrt_saved_model_float16 saved_model_madnet_${DATASET}_${H}x${W}
mv tflite_from_saved_model/tensorrt_saved_model_float32 saved_model_madnet_${DATASET}_${H}x${W}
rm -rf tflite_from_saved_model

H=360
W=640
DATASET=kitti
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs \
--output_coreml
python3 -m tf2onnx.convert \
--opset 11 \
--tflite tflite_from_saved_model/model_float32.tflite \
--output tflite_from_saved_model/model_float32.onnx \
--inputs-as-nchw model/left_img,model/right_img
python3 -m onnxsim tflite_from_saved_model/model_float32.onnx tflite_from_saved_model/model_float32.onnx
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir tflite_from_saved_model/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir tflite_from_saved_model/openvino/FP16
mkdir -p tflite_from_saved_model/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m tflite_from_saved_model/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o tflite_from_saved_model/openvino/myriad/model.blob
mv tflite_from_saved_model/* saved_model_madnet_${DATASET}_${H}x${W}
cp -r saved_model_madnet_${DATASET}_${H}x${W}/variables tflite_from_saved_model
cp saved_model_madnet_${DATASET}_${H}x${W}/saved_model.pb tflite_from_saved_model
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_tftrt
mv tflite_from_saved_model/tensorrt_saved_model_float16 saved_model_madnet_${DATASET}_${H}x${W}
mv tflite_from_saved_model/tensorrt_saved_model_float32 saved_model_madnet_${DATASET}_${H}x${W}
rm -rf tflite_from_saved_model

H=480
W=640
DATASET=kitti
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs \
--output_coreml
python3 -m tf2onnx.convert \
--opset 11 \
--tflite tflite_from_saved_model/model_float32.tflite \
--output tflite_from_saved_model/model_float32.onnx \
--inputs-as-nchw model/left_img,model/right_img
python3 -m onnxsim tflite_from_saved_model/model_float32.onnx tflite_from_saved_model/model_float32.onnx
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir tflite_from_saved_model/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir tflite_from_saved_model/openvino/FP16
mkdir -p tflite_from_saved_model/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m tflite_from_saved_model/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o tflite_from_saved_model/openvino/myriad/model.blob
mv tflite_from_saved_model/* saved_model_madnet_${DATASET}_${H}x${W}
cp -r saved_model_madnet_${DATASET}_${H}x${W}/variables tflite_from_saved_model
cp saved_model_madnet_${DATASET}_${H}x${W}/saved_model.pb tflite_from_saved_model
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_tftrt
mv tflite_from_saved_model/tensorrt_saved_model_float16 saved_model_madnet_${DATASET}_${H}x${W}
mv tflite_from_saved_model/tensorrt_saved_model_float32 saved_model_madnet_${DATASET}_${H}x${W}
rm -rf tflite_from_saved_model

H=720
W=1280
DATASET=kitti
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_no_quant_float32_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_tfjs \
--output_coreml
python3 -m tf2onnx.convert \
--opset 11 \
--tflite tflite_from_saved_model/model_float32.tflite \
--output tflite_from_saved_model/model_float32.onnx \
--inputs-as-nchw model/left_img,model/right_img
python3 -m onnxsim tflite_from_saved_model/model_float32.onnx tflite_from_saved_model/model_float32.onnx
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP32 \
--output_dir tflite_from_saved_model/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model tflite_from_saved_model/model_float32.onnx \
--data_type FP16 \
--output_dir tflite_from_saved_model/openvino/FP16
mkdir -p tflite_from_saved_model/openvino/myriad
${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64/myriad_compile \
-m tflite_from_saved_model/openvino/FP16/model_float32.xml \
-ip U8 \
-VPU_NUMBER_OF_SHAVES 4 \
-VPU_NUMBER_OF_CMX_SLICES 4 \
-o tflite_from_saved_model/openvino/myriad/model.blob
mv tflite_from_saved_model/* saved_model_madnet_${DATASET}_${H}x${W}
cp -r saved_model_madnet_${DATASET}_${H}x${W}/variables tflite_from_saved_model
cp saved_model_madnet_${DATASET}_${H}x${W}/saved_model.pb tflite_from_saved_model
saved_model_to_tflite \
--saved_model_dir_path saved_model_madnet_${DATASET}_${H}x${W} \
--output_tftrt
mv tflite_from_saved_model/tensorrt_saved_model_float16 saved_model_madnet_${DATASET}_${H}x${W}
mv tflite_from_saved_model/tensorrt_saved_model_float32 saved_model_madnet_${DATASET}_${H}x${W}
rm -rf tflite_from_saved_model

