docker run --gpus all -it --rm \
-v `pwd`:/home/user/workdir \
ghcr.io/pinto0309/openvino2tensorflow:latest

MODEL=bsrganx2
python3 set_static_shape.py --model ${MODEL}_HxW.onnx --height 64 --width 64
python3 set_static_shape.py --model ${MODEL}_HxW.onnx --height 96 --width 96
python3 set_static_shape.py --model ${MODEL}_HxW.onnx --height 128 --width 128
python3 set_static_shape.py --model ${MODEL}_HxW.onnx --height 160 --width 160
python3 set_static_shape.py --model ${MODEL}_HxW.onnx --height 180 --width 320
python3 set_static_shape.py --model ${MODEL}_HxW.onnx --height 240 --width 320

MODEL=bsrganx4
python3 set_static_shape.py --model ${MODEL}_HxW.onnx --height 64 --width 64
python3 set_static_shape.py --model ${MODEL}_HxW.onnx --height 96 --width 96
python3 set_static_shape.py --model ${MODEL}_HxW.onnx --height 128 --width 128
python3 set_static_shape.py --model ${MODEL}_HxW.onnx --height 160 --width 160
python3 set_static_shape.py --model ${MODEL}_HxW.onnx --height 180 --width 320
python3 set_static_shape.py --model ${MODEL}_HxW.onnx --height 240 --width 320

MODEL=bsrganx2
H=64
W=64
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}
rm -rf saved_model


H=96
W=96
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}
rm -rf saved_model

H=128
W=128
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}
rm -rf saved_model

H=160
W=160
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}
rm -rf saved_model

H=180
W=320
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}
rm -rf saved_model

H=240
W=320
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}
rm -rf saved_model



MODEL=bsrganx4
H=64
W=64
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}
rm -rf saved_model

H=96
W=96
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}
rm -rf saved_model

H=128
W=128
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}
rm -rf saved_model

H=160
W=160
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}
rm -rf saved_model

H=180
W=320
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}
rm -rf saved_model

H=240
W=320
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP32 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP32
$INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo.py \
--input_model ${MODEL}_${H}x${W}.onnx \
--data_type FP16 \
--output_dir ${MODEL}_${H}x${W}/openvino/FP16
openvino2tensorflow \
--model_path ${MODEL}_${H}x${W}/openvino/FP32/${MODEL}_${H}x${W}.xml \
--output_saved_model \
--output_pb \
--output_no_quant_float32_tflite \
--output_dynamic_range_quant_tflite \
--output_weight_quant_tflite \
--output_float16_quant_tflite \
--output_integer_quant_tflite \
--output_integer_quant_typ 'uint8' \
--string_formulas_for_normalization 'data / 255' \
--output_tfjs \
--output_coreml
mv saved_model/* ${MODEL}_${H}x${W}
mv ${MODEL}_${H}x${W}.onnx ${MODEL}_${H}x${W}
rm -rf saved_model
